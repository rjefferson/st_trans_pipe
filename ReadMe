
Description
-----------

A set of python routines which implements a transfer pipeline for STAR data reco on NERSC Cori. 
The agreed upon model is one in which the data mover & disk management are on the local site, 
pulling and probing the remote site for data & info.  The remote site has a transfer buffer in 
which a target+marker file pair are placed.  Finding the marker file triggers a pull from the 
remote site to local buffer (see transer_pipeline.py).  Success causes a local transfer status 
file to be set as 'done'. For clean up (see clean_pipe.py), the local site queries the remote transfer 
buffer and deletes its 'done' status files once the marker file is removed from the remote buffer. 
The remote site is also queried for the reversed transfers 'done' status files in order to remove
files from the local site's transfer buffer. 

Codes
-----

transfer_pipeline.py

Queries remote buffer, copies new files to local buffer via globus-url-copy, creates transfer status file

Run as:  transfer_pipeline.py [--config-file config_file_name] [ many other options in code ]

clean_pipe.py

Run as:  clean_pipe.py [--config-file config_file_name] [many other options]

1) Queries remote transfer buffer and cleans local status files when remote marker file is gone
2) Queries remote transfer status and cleans local buffer when transfer "done" is found

process_commands.py

Helper routines used by both for logging and processing commands in a way that allows 
one to break on timeouts.  This is particularly useful for remote calls via globus-url-copy 
that can hang with network issues.

config_file_example.dat

simple example for overwriting arguments (defaults or cli inputs) using a config file. 

